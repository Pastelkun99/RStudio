install.packages("wordcloud")
library(wordcloud)
word <- c("인천광역시", "강화군", "옹진군")
frequency <- c(651, 85, 61)
wordcloud(word, frequency, colors = "blue", random.order = FALSE)
wordcloud(word, frequency, random.order = FALSE, random.color = FALSE, colors = rainbow(length(word)))
wordcloud(word, frequency, colors = "blue", random.order = FALSE)
wordcloud(word, frequency, colors = "blue", random.order = FALSE)
wordcloud(word, frequency, random.order = FALSE, random.color = FALSE, colors = rainbow(length(word)))
wordcloud(word, frequency, random.order = FALSE, random.color = FALSE, colors = rainbow(length(word)))
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
# 이제 사전을 설정해야 하는데 KoNLP에서는 NIA라는 사전이 98만여 개의 단어로 구성되어 있다.
# 이 사전을 이용하자.
useNIADic() # 설치가 꽤 걸린다.
useNIADic()
library(KoNLP)
library(dplyr)
useNIADic()
# 다양한 단어 색 출력을 위한 팔레트 패키지
install.packages("RColorBrewer")
# 다양한 단어 색 출력을 위한 팔레트 패키지
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(RColorBrewer)
display.brewer.all()
display.brewer.pal(8, name = "Dark2")
display.brewer.pal(8, name = "Dark2")
install.packages("KoNLP")
library(KoNLP)
library(dplyr)
useNIADic()
txt <- readLines("hiphop.txt")
txt <- readLines("hiphop.txt")
txt
install.packages("string")
library(string)
library(stringr)
txt <- str_replace_all(txt, "\\W", " ")
txt
extractNoun("대한민국의 영토는 한반도와 그 부석도서로 한다.")
nouns <- extractNoun(txt)
class(nouns)
wordcount <- table(unlist(nouns))
class(wordcount)
View(wordcount)
df_word <- as.data.frame(wordcount, stringAsFactors = F)
class(df_word)
View(df_word)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word <- filter(df_word, nchar(word) >= 2)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top_20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
View(top_20)
df_word <- filter(df_word, nchar(df_word) >= 2)
df_word <- filter(df_word, nchar(word) >= 2)
install.packages("string")
library(string)
library(stringr)
# 문장에 이모티콘이나 특수문자가 포함되어 있으면 분석에 오류가 발생할 수 있다.
# 하여 문자처리 패키지인 string의 str_replace_all()을 사용하여 특수문자를 빈칸으로 처리하자.
install.packages("stringr")
install.packages("stringr")
library(stringr)
txt <- str_replace_all(txt, "\\W", " ")
library(wordcloud)
word <- c("인천광역시", "강화군", "옹진군")
frequency <- c(651, 85, 61)
wordcloud(word, frequency, colors = "blue", random.order = FALSE)
wordcloud(word, frequency, random.order = FALSE, random.color = FALSE, colors = rainbow(length(word)))
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(KoNLP)
library(dplyr)
txt <- readLines("hiphop.txt")
txt
library(stringr)
txt <- str_replace_all(txt, "\\W", " ")
txt
extractNoun("대한민국의 영토는 한반도와 그 부석도서로 한다.")
# 그럼 위의 가사에서 명사를 추출하고, 각 단어가 몇번씩 사용되었는지 빈도표를 만들자.
nouns <- extractNoun(txt)
class(nouns)
wordcount <- table(unlist(nouns))
class(wordcount)
View(wordcount)
df_word <- as.data.frame(wordcount, stringAsFactors = F)
class(df_word)
View(df_word)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word <- filter(df_word, nchar(word) >= 2)
library(dplyr)
# 보통 한글자로 된 단어는 의미가 없는 경우가 많아 nchar()를 이용하여 두글자 이상으로 된 단어만 추출하자.
df_word <- filter(df_word, nchar(word)>=2)
class(df_word)
class(word)
class(df_word$word)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- as.data.frame(wordcount, stringAsFactors = F)
class(df_word)
class(df_word$word)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
class(df_word$word)
# 테이블을 데이터프레임구조로 바꾸자.
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
class(df_word$word)
df_word <- filter(df_word, nchar(word)>=2)
df_word
top_20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
View(top_20)
library(wordcloud)
pal <- brewer.pal(8, "Dark2")
set.seed(1234)
wordcloud(words = df_word$word, # 나타낼 단어,
freq = df_word$freq,  # 단어 빈도
min.freq = 5,         # 최소 단어 빈도
max.words = 100,      # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치, TRUE이면 랜덤배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.2),    # 단어 크기 비율
colors = pal)         # 색상 목록
library(wordcloud)
library(RColorBrewer)
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_131")
Sys.setlocale(category = "LC_CTYPE", locale = "ko_KR.UTF-8")
library(KoNLP)
library(dplyr)
useNIADic()
presidenttxt <- readlines("President.txt")
library(dplyr)
presidenttxt <- readlines("President.txt")
presidenttxt <- readLines("President.txt")
Sys.setlocale(category = "LC_CTYPE", locale = "ko_KR.UTF-8")
presidenttxt
presidenttxt <- readLines("President.txt", encoding = "UTF-8")
presidenttxt
library(stringr)
presidenttxt <- str_replace_all(presidenttxt, "\\W", " ")
prenouns <- extractNoun(presidenttxt)
class(prenouns)
prewordcount <- table(unlist(prenouns))
# 테이블 대로 변환되었다.
class(wordcount)
class(prewordcount)
df_preword <- as.data.frame(prewordcount, stringsAsFactors = F)
View(df_preword)
df_preword <- rename(df_word,
word = Var1,
freq = Freq)
View(df_preword)
df_preword <- rename(df_preword,
word = Var1,
freq = Freq)
View(df_preword)
pretop_20 <- df_preword %>%
arrange(desc(freq)) %>%
head(20)
prepal <- brewer.pal(8, "Dark2")
set.seed(9999)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(4, 0.2),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(4, 0.2),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(10, 5),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(8, 0.7),
colors = prepal)
df_preword <- filter(df_preword, nchar(word)>=2)
pretop_20 <- df_preword %>%
arrange(desc(freq)) %>%
head(20)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(8, 0.7),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
pretop_50 <- df_preword %>%
arrange(desc(freq)) %>%
head(50)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 100,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
View(df_preword)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 5,
max.words = 300,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 2,
max.words = 300,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 3,
max.words = 300,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
wordcloud(words = df_preword$word,
freq = df_preword$freq,
min.freq = 2,
max.words = 300,
random.order = F,
rot.per = .1,
scale = c(6, 0.4),
colors = prepal)
twitter <- read.csv("twitter.csv",
stringsAsFactors = F,
fileEncoding = "UTF-8")
View(twitter)
library(wordcloud)
library(RColorBrewer)
library(KoNLP)
library(dplyr)
library(stringr)
library(ggplot2)
str(twitter)
class(twitter)
dim(twitter)
twitter <- rename(twitter, no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter$tw <- str_replace_all(twitter$tw, "\\W", " ")
head(twitter$tw, 5)
nouns <- extractNoun(twitter$tw)
wordcount <- table(unlist(nouns))
class(wordcount)
View(wordcount)
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
class(df_word)
str(df_word)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word <- filter(df_word, nchar(word) >= 2)
df_word
top_20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top_20
order <- arrange(top_20, freq)
order
ggplot(data = top_20, aes(x = word, y = freq)) +
ylim(0, 2800) +
geom_col(fill = "black", colour = "yellow") +
coord_flip() +
scale_x_discrete(limit = order$word) + # 빈도순으로 막대 정렬
geom_text(aes(label = freq), hjust = -0.3)
pal <- brewer.pal(8, "Dark2")
pal1 <- brewer.pal(9, "Blues")[5:9]
set.seed(1234)
wordcloud(words = df_word$word,         # 단어
freq = df_word$freq,          # 빈도
min.freq = 10,                # 최소단어 빈도
max.words = 100,              # 최대단어 빈도
random.order = FALSE,         # 단어 빈도 높은 것을 중앙에 배치
rot.per = .1,                 # 회전 단어 비율
scale = c(6, 0.2),            # 단어 크기 목록
colors = pal)
ggplot(data = top_20, aes(x = word, y = freq)) +
ylim(0, 2800) +
geom_col(fill = "black", colour = "yellow") +
coord_flip() +
scale_x_discrete(limit = order$word) + # 빈도순으로 막대 정렬
geom_text(aes(label = freq), hjust = -0.3)
wordcloud(words = df_word$word,         # 단어
freq = df_word$freq,          # 빈도
min.freq = 10,                # 최소단어 빈도
max.words = 100,              # 최대단어 빈도
random.order = FALSE,         # 단어 빈도 높은 것을 중앙에 배치
rot.per = .1,                 # 회전 단어 비율
scale = c(6, 0.2),            # 단어 크기 목록
colors = pal)                 # 색상 목록
class(df_word)
View(df_word)
word
View(word)
df_word$word <- gsub("사실", "", order)
df_word$word <- gsub("사실", "", df_word$word)
wordcloud(words = df_word$word,         # 단어
freq = df_word$freq,          # 빈도
min.freq = 10,                # 최소단어 빈도
max.words = 100,              # 최대단어 빈도
random.order = FALSE,         # 단어 빈도 높은 것을 중앙에 배치
rot.per = .1,                 # 회전 단어 비율
scale = c(6, 0.2),            # 단어 크기 목록
colors = pal)
df_word$word <- gsub("북한", "", df_word$word)
wordcloud(words = df_word$word,         # 단어
freq = df_word$freq,          # 빈도
min.freq = 10,                # 최소단어 빈도
max.words = 100,              # 최대단어 빈도
random.order = FALSE,         # 단어 빈도 높은 것을 중앙에 배치
rot.per = .1,                 # 회전 단어 비율
scale = c(6, 0.2),            # 단어 크기 목록
colors = pal)
View(twitter)
